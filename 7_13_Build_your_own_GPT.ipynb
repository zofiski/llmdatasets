{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOidJoigcQpTH2/aDGSo6Y3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zofiski/llmdatasets/blob/main/7_13_Build_your_own_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.youtube.com/watch?v=TSqkKH4zuZY code tutorial"
      ],
      "metadata": {
        "id": "83tg_AZLhKKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "hiU0yFG8Tn_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rvphl_7TfMF"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_cosine_with_hard_restarts_schedule_with_warmup"
      ],
      "metadata": {
        "id": "W_5YLbx6T_sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate"
      ],
      "metadata": {
        "id": "-STKuNyQayys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "ZVUIwl3cbFMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformers.__version__, accelerate.__version__"
      ],
      "metadata": {
        "id": "MUxie0Bqa2mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "iPLTcI_RXoZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = GPT2Config(\n",
        "    vocab_size= 131072,\n",
        "    #n_positions=1024,\n",
        "    #n_ctx=1024,\n",
        "    n_embd=7680,\n",
        "    n_layer=70,\n",
        "    n_head=40,\n",
        "    use_cache=True\n",
        ")"
      ],
      "metadata": {
        "id": "XUY4TSTcUGiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Config, GPT2Model #Inserted here\n",
        "configuration = GPT2Config()\n",
        "model = GPT2Model(configuration)\n",
        "configuration = model.config\n"
      ],
      "metadata": {
        "id": "A0hFBPjxeG3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= GPT2Tokenizer.from_pretrained('gpt2', vocab_size=config.vocab_size)"
      ],
      "metadata": {
        "id": "JZ04Lav2U25n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "NWt2fKf5VREl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "id": "ROWkR4EUWX2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('text', data_files='https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt')"
      ],
      "metadata": {
        "id": "y4jB79reWyMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length'))"
      ],
      "metadata": {
        "id": "OVtyartoVVNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset)\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "8BDyfxysr2cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\n",
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers"
      ],
      "metadata": {
        "id": "xccOFwu0ZCPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=16,\n",
        "    max_grad_norm=0.3,\n",
        "    learning_rate=6e-5,\n",
        "    fp16=False,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        ")"
      ],
      "metadata": {
        "id": "AbGMgn1-YIM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize_the_Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    #eval_dataset=tokenized_dataset[\"validation\"], #https://discuss.huggingface.co/t/keyerror-validation-when-trying-to-use-validation-dataset/9524/2\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "xx_nNAI3bZhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}